%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                                                                 %
%                            CHAPTER                              %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\chapter{Initial Difficulties during the implementation}

\textit{Disclaimer: The purpose of this chapter is more to show the learning process I had to go through in order to achieve a suitable implementation for the genome mapping problem. I had to learn some new programming techniques such as HLS, SDSoC \dots especially for this thesis, since I did not have any experience in it yet. This chapter might be less applicable if the reader is interested in the science and implementation approach of the genome mapping problem, but can be of interest if the reader is also new to the mentioned programming techniques.}

\section{Using Vivado HLS and Xilinx SDK}

\subsection{learning HLS in examples}

Ik moet nog starten met HLS, nog nooit gedaan.

learning HLS

lab1: BASIC WORKFLOW: How to make project, difference between sources and test bench, GUI and it's components, simulation, synthesis (=> estimate and Gantt chart), viewing resulting VHDL code, co-simulation, view simulation waveforms, IP Core export, creating multiple solutions and comparing, setting a directive (like unroll a loop).

lab2: DATA TYPES adhv FIR filter: floating point VS fixed point, saturation with fixed point, fixed point with larger internal bit-width (LSB laten vallen), 

lab3: INTERFACES:
- basic argument-level interfaces (ap\_vld, ap\_none, ap\_hs)
- block-level interface of pipelined component (pipeline on the top function)

lab4: ARRAYS: Sequential, pipelining internal loop, rewind parameter, top function pipelining, array map, array partition (cyclic and complete), array reshape technique

\subsection{Learning how to program target board}

hello world via Xilinx SDK => baremetal 
-> zelf kiezen waar uitgevoerd + dataverplaatsingen zelf implementeren


\section{SDSoC}

Op een Linuxdistributie.

Snel functie verplaatsen van PS naar PL.

gebruikt ook delen van HLS

\subsection{learning process on matrix multiplication example in SDSoC}

Eerste test: matrixmultiplicatie

lab1: INTRODUCTION: basic workflow, working with hardware accelerators, running the project, ...

lab2: PERFORMANCE ESTIMATION: rescource utilization, comparing software and hardware implementations, overall speedup comparison (all using LINUX hosted)

lab3: diff between ACP, AFI and GP
	ACP	Hardware functions have cache coherent access to DDR via the PS L2 cache.
	AFI (HP)	Hardware functions have fast non-cache coherent access to DDR via the PS memory controller.
	GP	Processor directly writes/reads data to/from hardware function. Inefficient for large data transfers.
+ error reporting (opening log files to see more information).
Additional: the hardware functions and DMAs can only access the physical address space (not virtual) => DMA that can handle a list of pages for a single array is known as Scatter-Gather DMA. (malloc(), sds\_alloc()) Typically sds\_alloc = best (area and performance) but uses physical memory (minder van beschikbaar dan virtueel).

lab4: directives to optimize the accelerator

lab5: task level pipelining
	=> speedup x3 theoretical, probably I make some mistakes

lab6: DEBUG

lab7: HARDWARE DEBUG: trace feature: what is the application doing? (software, hardware, transfer, recieve)

lab8: EMULATION
